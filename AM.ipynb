{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a68b24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip freeze > requorements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c1d62",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "ARIMA (AutoRegressive Integrated Moving Average) model is a popular time series analysis and forecasting method used in econometrics, finance, and other fields. It is a class of statistical models that captures the stochastic nature of a time series and its underlying patterns.\n",
    "\n",
    "The ARIMA model has three components:\n",
    "\n",
    "Autoregression (AR) - A regression model that uses lagged values of the time series to predict its current value.\n",
    "\n",
    "Moving Average (MA) - A model that uses the past errors of the time series to predict its current value.\n",
    "\n",
    "Integration (I) - A differencing process that transforms a non-stationary time series into a stationary one by computing the differences between consecutive observations.\n",
    "\n",
    "The notation for an ARIMA model is ARIMA(p, d, q), where:\n",
    "\n",
    "* p: the order of the autoregressive part\n",
    "* d: the degree of differencing\n",
    "* q: the order of the moving average part\n",
    "\n",
    "The selection of the values for p, d, and q is typically done using statistical methods such as the Akaike information criterion (AIC) or the Bayesian information criterion (BIC). Once the optimal values for p, d, and q are determined, the ARIMA model can be used to make predictions about future values of the time series. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f9082",
   "metadata": {},
   "source": [
    "### Assumptions\n",
    "\n",
    ">Stationarity: the time series should be stationary. This means that the mean, variance, and autocorrelation of the series should remain constant over time. If the series is non-stationary, it can be made stationary through differencing.\n",
    "\n",
    ">No seasonality: ARIMA models assume that the time series does not have any seasonal patterns. If there is seasonality in the data, a seasonal ARIMA (SARIMA) model should be used instead.\n",
    "\n",
    ">No outliers: ARIMA models assume that there are no extreme values or outliers in the time series. Outliers can be identified and removed from the data to improve the accuracy of the model.\n",
    "\n",
    ">No autocorrelation in residuals: The residuals (the difference between the observed values and the predicted values) should be independent and identically distributed (i.e., have no autocorrelation). If there is autocorrelation in the residuals, it indicates that the model is not capturing all the information in the data.\n",
    "\n",
    ">Normally distributed residuals: The residuals should be normally distributed with a mean of zero. If the residuals are not normally distributed, it may indicate that the model is not appropriate for the data or that there are other factors affecting the series that are not accounted for in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86650bc1",
   "metadata": {},
   "source": [
    "### Steps\n",
    "\n",
    "* Import the necessary libraries: import pandas, numpy, matplotlib, and statsmodels libraries.\n",
    "\n",
    "* Load the data: Load the data into a pandas DataFrame and set the 'Date' column as the index.\n",
    "\n",
    "* Convert the data to time series: Convert the DataFrame into a time series using the 'to_datetime' function.\n",
    "\n",
    "* Visualize the data: Plot the data using the 'plot' function to visualize the trend, seasonality, and any other patterns in the data.\n",
    "\n",
    "* Stationarize the data: Check if the time series is stationary using the 'adf_test' function from the statsmodels library. If the time series is not stationary, you can apply differencing to make it stationary.\n",
    "\n",
    "* Determine the parameters: Determine the values of p, d, and q for the ARIMA model by analyzing the ACF and PACF plots.\n",
    "\n",
    "* Build the ARIMA model: Build the ARIMA model using the 'ARIMA' function from the statsmodels library, passing in the values of p, d, and q.\n",
    "\n",
    "* Fit the model: Fit the model to the data using the 'fit' method.\n",
    "\n",
    "* Forecast: Forecast the values for April 2024 using the 'forecast' method, passing in the number of periods you want to forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6b42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eef4f70",
   "metadata": {},
   "source": [
    "# 2. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bb7563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and parse data column\n",
    "euro = pd.read_csv('EURO.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "# historical data for exogenous variables\n",
    "df_inflation = pd.read_csv('/home/munyao/Desktop/flat_iron_school/clients/lusa/data/Inflation Rates.csv')\n",
    "df_inflation['Date'] = pd.to_datetime(df_inflation['Year'], format='%Y')\n",
    "df_inflation.set_index('Date', inplace=True)\n",
    "\n",
    "# foreign trade\n",
    "file_path = \"/home/munyao/Desktop/flat_iron_school/clients/lusa/data/Foreign Trade Summary (Ksh Million).csv\"\n",
    "df_foreign_trade = pd.read_csv(file_path)\n",
    "df_foreign_trade['Date'] = pd.to_datetime(df_foreign_trade['Year'], format='%Y')\n",
    "df_foreign_trade.set_index('Date', inplace=True) \n",
    "\n",
    "#  GDP\n",
    "file_path = \"/home/munyao/Desktop/flat_iron_school/clients/lusa/data/Annual GDP.csv\"\n",
    "gdp_df = pd.read_csv(file_path)\n",
    "gdp_df = gdp_df.iloc[:-1]  \n",
    "gdp_df['Date'] = pd.to_datetime(gdp_df['Year'], format='%Y')\n",
    "gdp_df.set_index('Date', inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b13e9",
   "metadata": {},
   "source": [
    "### 2.0.1 Data Profile Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a70b1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccesary libraries\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# generate data report using the pandas profiling\n",
    "euro_profile = ProfileReport(euro, title=\"EURO Data Data Report\")\n",
    "foreign_trade_profile = ProfileReport(df_foreign_trade, title=\"Foreign Trade Data Data Report\")\n",
    "gdp_profile = ProfileReport(gdp_df, title=\"EURO Data Data Report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f74fbe9",
   "metadata": {},
   "source": [
    "### 2.0.2 Datasets Mergeing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddce70cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Annual Average Inflation</th>\n",
       "      <th>12-Month Inflation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>January</td>\n",
       "      <td>7.95</td>\n",
       "      <td>8.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>December</td>\n",
       "      <td>7.66</td>\n",
       "      <td>9.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>November</td>\n",
       "      <td>7.38</td>\n",
       "      <td>9.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>October</td>\n",
       "      <td>7.48</td>\n",
       "      <td>9.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>September</td>\n",
       "      <td>6.81</td>\n",
       "      <td>9.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>May</td>\n",
       "      <td>14.61</td>\n",
       "      <td>14.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>April</td>\n",
       "      <td>13.76</td>\n",
       "      <td>16.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>March</td>\n",
       "      <td>13.07</td>\n",
       "      <td>14.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>February</td>\n",
       "      <td>12.60</td>\n",
       "      <td>13.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>January</td>\n",
       "      <td>12.27</td>\n",
       "      <td>14.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Month  Annual Average Inflation  12-Month Inflation\n",
       "Year                                                         \n",
       "2023    January                      7.95                8.98\n",
       "2022   December                      7.66                9.06\n",
       "2022   November                      7.38                9.48\n",
       "2022    October                      7.48                9.59\n",
       "2022  September                      6.81                9.18\n",
       "...         ...                       ...                 ...\n",
       "2005        May                     14.61               14.78\n",
       "2005      April                     13.76               16.02\n",
       "2005      March                     13.07               14.15\n",
       "2005   February                     12.60               13.94\n",
       "2005    January                     12.27               14.87\n",
       "\n",
       "[218 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5998ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the datasets\n",
    "df = pd.merge(df_exchange, df_inflation, how='left', left_index=True, right_index=True)\n",
    "#df = pd.merge(df, df_unemployment, how='left', left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffcf08a",
   "metadata": {},
   "source": [
    "## 2.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd7602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview EURO data frame\n",
    "euro.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bed8c7",
   "metadata": {},
   "source": [
    "##### Check for Missing values and Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e96899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicated rows \n",
    "print(f\"The data frame has {euro.duplicated().sum()} duplicated rows\")\n",
    "print()\n",
    "# drop the duplicated rows based on all columns\n",
    "df = euro.drop_duplicates()\n",
    "\n",
    "print(f\"The data frame has {df.duplicated().sum()} duplicated rows after dropping the duplicates\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e3aef0",
   "metadata": {},
   "source": [
    "##### Check for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb14c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccesary libraries\n",
    "import seaborn as sns\n",
    "\n",
    "# create a boxplot for each column\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.boxplot(data=df[['Mean', 'Buy', 'Sell']], palette='Set3')\n",
    "\n",
    "# set the plot title and y-axis label\n",
    "plt.title('Boxplot of Exchange Rates')\n",
    "plt.ylabel('Exchange Rate')\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02042c2",
   "metadata": {},
   "source": [
    ">No outliers detected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb0468",
   "metadata": {},
   "source": [
    "## 3.  Data Visualization\n",
    "visualize the trend, seasonality, and any other patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a2610f",
   "metadata": {},
   "source": [
    "### 3.1.Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66427c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stationery_display(df,cols):\n",
    "#     # set figure size\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "\n",
    "#     # plot the rolling mean and rolling standard deviation\n",
    "#     buy = df['Buy']\n",
    "#     rolmean = buy.rolling(window=12).mean()\n",
    "#     rolstd = buy.rolling(window=12).std()\n",
    "#     plt.plot(buy, color='blue', label='Buy')\n",
    "#     plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "#     plt.plot(rolstd, color='black', label='Rolling Std')\n",
    "#     plt.title('Rolling Mean & Standard Deviation of Buy')\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Exchange Rate')\n",
    "#     plt.legend()\n",
    "\n",
    "#     # show plot\n",
    "#     plt.show()\n",
    "        \n",
    "# stationery_display(euro,\"Mean\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba4fc6",
   "metadata": {},
   "source": [
    "#### 3.2. Autocorrelation\n",
    "The ACF plot shows the correlation of the time series with its lagged values. The PACF plot shows the correlation of the time series with its lagged values after removing the effects of the intermediate lags.\n",
    "\n",
    "Identify the values for p and q: \n",
    "* The value of p is the lag at which the PACF plot first crosses the upper confidence interval. \n",
    "* The value of q is the lag at which the ACF plot first crosses the upper confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a3dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# increase plot size\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "\n",
    "# plot ACF\n",
    "plot_acf(df['Mean'], lags=30)\n",
    "\n",
    "plt.axhline(y=-1.96/np.sqrt(len(df)), linestyle='--', color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(df)), linestyle='--', color='gray')\n",
    "plt.title('Autocorrelation Function (ACF) of Mean')\n",
    "plt.xlabel('Lags')\n",
    "plt.ylabel('Correlation')\n",
    "plt.show()\n",
    "\n",
    "# Plot PACF\n",
    "plot_pacf(df['Mean'], lags=30)\n",
    "plt.axhline(y=-1.96/np.sqrt(len(df)), linestyle='--', color='gray')\n",
    "plt.axhline(y=1.96/np.sqrt(len(df)), linestyle='--', color='gray')\n",
    "plt.title('Partial Autocorrelation Function (PACF) of Mean')\n",
    "plt.xlabel('Lags')\n",
    "plt.ylabel('Correlation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c980b6ac",
   "metadata": {},
   "source": [
    ">The ACF plot shows a slow decay, and the PACF plot shows a sharp cutoff after lag p, a first-order difference is needed to make the time series stationary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd52c7",
   "metadata": {},
   "source": [
    "#### 3.3. Stationarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d715c",
   "metadata": {},
   "source": [
    "####  Stationarity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to test \n",
    "def test_stationarity(series):\n",
    "    # augmented Dickey-Fuller test\n",
    "    adf_result = adfuller(series)\n",
    "    print('Augmented Dickey-Fuller Test:')\n",
    "    print('ADF Statistic: %f' % adf_result[0])\n",
    "    print('p-value: %f' % adf_result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in adf_result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "    if adf_result[0] < adf_result[4]['5%']:\n",
    "        print('ADF test indicates series is stationary')\n",
    "    else:\n",
    "        print('ADF test indicates series is non-stationary')\n",
    "\n",
    "    # kwiatkowski-Phillips-Schmidt-Shin test\n",
    "    kpss_result = sm.tsa.stattools.kpss(series)\n",
    "    print('\\nKwiatkowski-Phillips-Schmidt-Shin Test:')\n",
    "    print('KPSS Statistic: %f' % kpss_result[0])\n",
    "    print('p-value: %f' % kpss_result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in kpss_result[3].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "    if kpss_result[0] < kpss_result[3]['5%']:\n",
    "        print('KPSS test indicates series is stationary')\n",
    "    else:\n",
    "        print('KPSS test indicates series is non-stationary')\n",
    "\n",
    "# call function\n",
    "test_stationarity(df['Mean'])        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ab8f10",
   "metadata": {},
   "source": [
    "## 4. Data PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6477cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop currency column\n",
    "final_df = euro.drop(\"Currency\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab162d6c",
   "metadata": {},
   "source": [
    "#####  Apply Differencing\n",
    "The time series is non-stationary, apply differencing to make it stationary.I will apply first-order differencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf850ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply first order differencing\n",
    "diff_y = final_df.diff(periods=1).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94479d55",
   "metadata": {},
   "source": [
    ">**After applying differencing, check for stationarity again, and these are results of the Augmented Dickey-Fuller test, the Kwiatkowski-Phillips-Schmidt-Shin test, and the Phillips-Perron test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9600e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function to test stationarity\n",
    "test_stationarity(diff_y[\"Mean\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eef1b3",
   "metadata": {},
   "source": [
    "## 5. Determine the Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d02555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccesary library\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "# Find the optimal order of the ARIMA model\n",
    "model = auto_arima(diff_y[\"Mean\"], seasonal=False, trace=True,\n",
    "                   suppress_warnings=True, error_action=\"ignore\")\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29679763",
   "metadata": {},
   "source": [
    "## 6. Modelling\n",
    "### kesur_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665ec37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the ARIMA model\n",
    "# AR order\n",
    "p = None  \n",
    "\n",
    "# differencing order\n",
    "d = None  \n",
    "\n",
    "# MA order\n",
    "q = None  \n",
    "\n",
    "kesur_mean = sm.tsa.ARIMA(df['Mean'], order=(2, 0, 3))\n",
    "kesur_sell = sm.tsa.ARIMA(df['Sell'], order=(2, 0, 3))\n",
    "kesur_buy = sm.tsa.ARIMA(df['Buy'], order=(1, 0, 3))\n",
    "\n",
    "# fit the model\n",
    "mean_results = kesur_mean.fit()\n",
    "sell_results = kesur_sell.fit()\n",
    "buy_results = kesur_buy.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4237984",
   "metadata": {},
   "source": [
    "### Forcast for Feb 24 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52728ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "euro.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb2693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast for 1 year\n",
    "forecast_periods = 12\n",
    "mean_forecast = mean_results.forecast(steps=forecast_periods)\n",
    "sell_forecast = sell_results.forecast(steps=forecast_periods)\n",
    "buy_forecast = buy_results.forecast(steps=forecast_periods)\n",
    "\n",
    "# print the forecasted values\n",
    "if len(mean_forecast) > 0:\n",
    "    print(\"Mean forecast for April 2024:\", mean_forecast.mean())\n",
    "else:\n",
    "    print(\"Error: Mean forecast array is empty\")\n",
    "    \n",
    "if len(sell_forecast) > 0:\n",
    "    print(\"Sell forecast for April 2024:\", sell_forecast.mean())\n",
    "else:\n",
    "    print(\"Error: Sell forecast array is empty\")\n",
    "\n",
    "if len(buy_forecast) > 0:\n",
    "    print(\"Buy forecast for April 2024:\", buy_forecast.mean())\n",
    "else:\n",
    "    print(\"Error: Buy forecast array is empty\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba9c1b",
   "metadata": {},
   "source": [
    "### Tune for Optimised Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57025bf3",
   "metadata": {},
   "source": [
    "# 7. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5fb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccesary libraries\n",
    "from scipy import stats\n",
    "\n",
    "# evaluate the model\n",
    "residuals = mean_results.resid\n",
    "\n",
    "# plot histogram of residuals\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.hist(residuals, bins=25, density=True, alpha=0.6, color='b')\n",
    "\n",
    "# plot normal distribution curve\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = stats.norm.pdf(x, np.mean(residuals), np.std(residuals))\n",
    "ax.plot(x, p, 'k', linewidth=2)\n",
    "ax.set_xlabel('Residuals')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Histogram of Residuals')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956f335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "residuals = sell_results.resid\n",
    "\n",
    "# plot histogram of residuals\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.hist(residuals, bins=25, density=True, alpha=0.6, color='b')\n",
    "\n",
    "# plot normal distribution curve\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = stats.norm.pdf(x, np.mean(residuals), np.std(residuals))\n",
    "ax.plot(x, p, 'k', linewidth=2)\n",
    "ax.set_xlabel('Residuals')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Histogram of Residuals')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89967b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "residuals = buy_results.resid\n",
    "\n",
    "# plot histogram of residuals\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.hist(residuals, bins=25, density=True, alpha=0.6, color='b')\n",
    "\n",
    "# plot normal distribution curve\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = stats.norm.pdf(x, np.mean(residuals), np.std(residuals))\n",
    "ax.plot(x, p, 'k', linewidth=2)\n",
    "ax.set_xlabel('Residuals')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Histogram of Residuals')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be612a",
   "metadata": {},
   "source": [
    ">residuals are normally distributed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arima_env",
   "language": "python",
   "name": "arima_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
